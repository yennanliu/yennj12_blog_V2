{
  
    
        "post0": {
            "title": "Scala Learning Resource",
            "content": ". 1) Coursera Scala specializations . Functional Programming Principles in Scala | Functional Program Design in Scala | Parallel programming | Big Data Analysis with Scala and Spark | Functional Programming in Scala Capstone | . 2) Scala Learn Resource . 3) Reference . Scala Standard Library API | Scala School!: A Scala tutorial by Twitter | A Tour of Scala: Tutorial introducing the main concepts of Scala | Scala Overview on StackOverflow: A list of useful questions sorted by topic | . 4) Scala books . https://github.com/yennanliu/data_science_repo/tree/master/book/scala | .",
            "url": "https://yennanliu.github.io/yennj12_blog_V2/2020/06/09/scala-learning-resource.html",
            "relUrl": "/2020/06/09/scala-learning-resource.html",
            "date": " • Jun 9, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Yelp Review Data Project",
            "content": "Repo : YelpReviews | Presentation : Presentation | Visualization : redash_dashboard | Dataset : yelp-dataset | . . Intro . Build a POC end-to-end BI app that mining the interest from Kaggle yelp dataset. | This dataset is a subset of Yelp&#39;s businesses, reviews, and user data. It was originally put together for the Yelp Dataset Challenge which is a chance for students to conduct research or analysis on Yelp&#39;s data and share their discoveries. In the dataset you&#39;ll find information about businesses across 11 metropolitan areas in four countries. | . Process . Step1 : data collect | Step 2 : data process | Step 3 : db modeling | Step 4 : data storage | Step 5 : ETL | Step 6 : data analysis / ML | Step 7 : data visualization | . Project focus . database modeling / schema design (per business understanding, use cases) | data process | analysis (think about how to leverage the data if as a Yelp PM) | framework design logic (why this database, why this schema, why this BI tool..) | . Demo . redash_dashboard | Presentation | .",
            "url": "https://yennanliu.github.io/yennj12_blog_V2/2020/06/05/yelp-review.html",
            "relUrl": "/2020/06/05/yelp-review.html",
            "date": " • Jun 5, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Build frameworks, not pipelines",
            "content": "Treat data engineering as product/service, rather than process . toc: true | badges: true | comments: true | sticky_rank: 1 | author: Yen | categories: [fastpages, jupyter] | . Video . Data Engineering Principles - Build frameworks, not pipelines” by Gatis Seja | . Key Takes Away . Understand the data consumers | Validation | Keep the raw data and intermediate steps data | Validate input and output | Monitoring is part of the product | . Ref . https://easydata.engineering/data-engineering-principles-according-to-gatis-seja | https://medium.com/@rchang/a-beginners-guide-to-data-engineering-the-series-finale-2cc92ff14b0 | .",
            "url": "https://yennanliu.github.io/yennj12_blog_V2/2020/06/05/build-framework-rather-pipeline.html",
            "relUrl": "/2020/06/05/build-framework-rather-pipeline.html",
            "date": " • Jun 5, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "NYC Taxi Trip Duration EDA notebook",
            "content": "Process : . - 0 LOAD DATA - 1 SIMPLE FEATURE EXTRACT - 2 DATA OVERVIEW -2.1 vendor_id -2.2 pickup_day &amp; dropoff_day -2.3 passenger_count -2.4 pickup &amp; dropoff locations (lon &amp; lat ) -2.5 store_and_fwd_flag -2.6 trip_duration - 3 FEATURE ENGINEERING - 4 FEATURE ANALYSIS -4.1 Duration VS. Distance -4.2 Driving Direction -4.3 Clustering -4.4 Avg speed, orders on clustering -4.5 Cyclic timestamp (week, hour, weekhour) - 5 DATA CLEANING ANALYSIS . File descriptions | . train.csv - the training set (contains 1458644 trip records) | test.csv - the testing set (contains 625134 trip records) | sample_submission.csv - a sample submission file in the correct format | . Data fields | . id - a unique identifier for each trip | vendor_id - a code indicating the provider associated with the trip record | pickup_datetime - date and time when the meter was engaged | dropoff_datetime - date and time when the meter was disengaged | passenger_count - the number of passengers in the vehicle (driver entered value) | pickup_longitude - the longitude where the meter was engaged | pickup_latitude - the latitude where the meter was engaged | dropoff_longitude - the longitude where the meter was disengaged | dropoff_latitude - the latitude where the meter was disengaged | store_and_fwd_flag - This flag indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server - Y=store and forward; N=not a store and forward trip | trip_duration - duration of the trip in seconds | . import pandas as pd, numpy as np %matplotlib inline %pylab inline import seaborn as sns import matplotlib.pyplot as plt . . Populating the interactive namespace from numpy and matplotlib . - 0) Load data . # load data df_train = pd.read_csv(&#39;~/NYC_Taxi_Trip_Duration/data/train.csv&#39;) df_test = pd.read_csv(&#39;~/NYC_Taxi_Trip_Duration/data/test.csv&#39;) sampleSubmission = pd.read_csv(&#39;~/NYC_Taxi_Trip_Duration/data/sample_submission.csv&#39;) . . df_train.head(2) . . id vendor_id pickup_datetime dropoff_datetime passenger_count pickup_longitude pickup_latitude dropoff_longitude dropoff_latitude store_and_fwd_flag trip_duration . 0 id2875421 | 2 | 2016-03-14 17:24:55 | 2016-03-14 17:32:30 | 1 | -73.982155 | 40.767937 | -73.964630 | 40.765602 | N | 455 | . 1 id2377394 | 1 | 2016-06-12 00:43:35 | 2016-06-12 00:54:38 | 1 | -73.980415 | 40.738564 | -73.999481 | 40.731152 | N | 663 | . -1) Simple feature extract . # help function def basic_feature_extract(df): df_= df.copy() # pickup df_[&quot;pickup_date&quot;] = pd.to_datetime(df_.pickup_datetime.apply(lambda x : x.split(&quot; &quot;)[0])) df_[&quot;pickup_hour&quot;] = df_.pickup_datetime.apply(lambda x : x.split(&quot; &quot;)[1].split(&quot;:&quot;)[0]) df_[&quot;pickup_year&quot;] = df_.pickup_datetime.apply(lambda x : x.split(&quot; &quot;)[0].split(&quot;-&quot;)[0]) df_[&quot;pickup_month&quot;] = df_.pickup_datetime.apply(lambda x : x.split(&quot; &quot;)[0].split(&quot;-&quot;)[1]) df_[&quot;pickup_weekday&quot;] = df_.pickup_datetime.apply(lambda x :pd.to_datetime(x.split(&quot; &quot;)[0]).weekday()) # dropoff # in case test data dont have dropoff_datetime feature try: df_[&quot;dropoff_date&quot;] = pd.to_datetime(df_.dropoff_datetime.apply(lambda x : x.split(&quot; &quot;)[0])) df_[&quot;dropoff_hour&quot;] = df_.dropoff_datetime.apply(lambda x : x.split(&quot; &quot;)[1].split(&quot;:&quot;)[0]) df_[&quot;dropoff_year&quot;] = df_.dropoff_datetime.apply(lambda x : x.split(&quot; &quot;)[0].split(&quot;-&quot;)[0]) df_[&quot;dropoff_month&quot;] = df_.dropoff_datetime.apply(lambda x : x.split(&quot; &quot;)[0].split(&quot;-&quot;)[1]) df_[&quot;dropoff_weekday&quot;] = df_.dropoff_datetime.apply(lambda x :pd.to_datetime(x.split(&quot; &quot;)[0]).weekday()) except: pass return df_ # get weekday import calendar def get_weekday(df): list(calendar.day_name) df_=df.copy() df_[&#39;pickup_week_&#39;] = pd.to_datetime(df_.pickup_datetime,coerce=True).dt.weekday df_[&#39;pickup_weekday_&#39;] = df_[&#39;pickup_week_&#39;].apply(lambda x: calendar.day_name[x]) return df_ # get trip duration def get_duration(df): df_= df.copy() df_[&#39;trip_duration_cal&#39;] = pd.to_datetime(df_[&#39;dropoff_datetime&#39;]) - pd.to_datetime(df_[&#39;pickup_datetime&#39;]) return df_ . . # one may take few minutes df_train_ = basic_feature_extract(df_train) . . df_train_ = get_duration(df_train_) df_train_ = get_weekday(df_train_) . . //anaconda/envs/g_dash/lib/python3.4/site-packages/ipykernel_launcher.py:30: FutureWarning: the coerce=True keyword is deprecated, use errors=&#39;coerce&#39; instead . - 2) Data overview . df_train.info() . . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1458644 entries, 0 to 1458643 Data columns (total 11 columns): id 1458644 non-null object vendor_id 1458644 non-null int64 pickup_datetime 1458644 non-null object dropoff_datetime 1458644 non-null object passenger_count 1458644 non-null int64 pickup_longitude 1458644 non-null float64 pickup_latitude 1458644 non-null float64 dropoff_longitude 1458644 non-null float64 dropoff_latitude 1458644 non-null float64 store_and_fwd_flag 1458644 non-null object trip_duration 1458644 non-null int64 dtypes: float64(4), int64(3), object(4) memory usage: 122.4+ MB . train data set has 1458644 trip records (every ride per record), no missing values | . df_train_.head(1) . . id vendor_id pickup_datetime dropoff_datetime passenger_count pickup_longitude pickup_latitude dropoff_longitude dropoff_latitude store_and_fwd_flag ... pickup_month pickup_weekday dropoff_date dropoff_hour dropoff_year dropoff_month dropoff_weekday trip_duration_cal pickup_week_ pickup_weekday_ . 0 id2875421 | 2 | 2016-03-14 17:24:55 | 2016-03-14 17:32:30 | 1 | -73.982155 | 40.767937 | -73.96463 | 40.765602 | N | ... | 03 | 0 | 2016-03-14 | 17 | 2016 | 03 | 0 | 00:07:35 | 0 | Monday | . 1 rows × 24 columns . 2-1) vendor_id . df_train.vendor_id.value_counts() . . 2 780302 1 678342 Name: vendor_id, dtype: int64 . Vendor_id means id of vendors, here we can see there are 2 vendors serve in this NYC taxi record, they have similar ride counts . 2-2) pickup_day &amp; dropoff_day . fig, ax = plt.subplots(ncols=2, sharey=True) fig.set_size_inches(12, 5) ax[0].plot(df_train_.groupby(&#39;pickup_date&#39;).count()[&#39;id&#39;], &#39;go-&#39;, alpha=0.5) ax[1].plot(df_train_.groupby(&#39;dropoff_date&#39;).count()[&#39;id&#39;], &#39;bo-&#39;, alpha=0.5) ax[0].set(xlabel=&#39;date&#39;, ylabel=&#39;Count&#39;,title=&quot;pickup counts&quot;) ax[1].set(xlabel=&#39;date&#39;, ylabel=&#39;Count&#39;,title=&quot;dropoff counts&quot;) plt.show() . . The orders countssudden fail in 2016-01-23, need to check deeper to see if this affect data quality . | Averagely 7000 - 9000 counts of orders (pickup) per day. . | . - 2-3) passenger_count . df_train_.groupby([&#39;pickup_date&#39;]).sum()[&#39;passenger_count&#39;].plot() df_train_.groupby([&#39;dropoff_date&#39;]).sum()[&#39;passenger_count&#39;].plot() . . &lt;matplotlib.axes._subplots.AxesSubplot at 0x1783c78d0&gt; . df_train_.passenger_count.value_counts(sort=False) . . 0 60 1 1033540 2 210318 3 59896 4 28404 5 78088 6 48333 7 3 8 1 9 1 Name: passenger_count, dtype: int64 . Averagely 12k - 16k passengers per day | Most taxi take 1 passengers per ride, but some numbers like 0,7,8,9 maybe are outliers | . 2-4) pickup &amp; dropoff locations (lon &amp; lat ) . # https://www.kaggle.com/misfyre/in-depth-nyc-taxi-eda-also-w-animation # folloing ref above, here I drop outliers and do geo data visualization # (drop data point &gt; 95% and &lt; 5%) . # pickup sns.lmplot(x=&quot;pickup_longitude&quot;, y=&quot;pickup_latitude&quot;, fit_reg=False, size=9, scatter_kws={&#39;alpha&#39;:0.3,&#39;s&#39;:5}, data=df_train_[( df_train_.pickup_longitude&gt;df_train_.pickup_longitude.quantile(0.005)) &amp;(df_train_.pickup_longitude&lt;df_train_.pickup_longitude.quantile(0.995)) &amp;(df_train_.pickup_latitude&gt;df_train_.pickup_latitude.quantile(0.005)) &amp;(df_train_.pickup_latitude&lt;df_train_.pickup_latitude.quantile(0.995))]) plt.xlabel(&#39;Pickup Longitude&#39;); plt.ylabel(&#39;Pickup Latitude&#39;); plt.show() . . # dropoff sns.lmplot(x=&quot;dropoff_longitude&quot;, y=&quot;dropoff_latitude&quot;,fit_reg=False, size=9, scatter_kws={&#39;alpha&#39;:0.3,&#39;s&#39;:5}, data=df_train_[( df_train_.dropoff_longitude&gt;df_train_.dropoff_longitude.quantile(0.005)) &amp;(df_train_.dropoff_longitude&lt;df_train_.dropoff_longitude.quantile(0.995)) &amp;(df_train_.dropoff_latitude&gt;df_train_.dropoff_latitude.quantile(0.005)) &amp;(df_train_.dropoff_latitude&lt;df_train_.dropoff_latitude.quantile(0.995))]) plt.xlabel(&#39;dropoff Longitude&#39;); plt.ylabel(&#39;dropoff Latitude&#39;); plt.show() . . We get an very interesting outcome from this visualization : . Manhattan get MOST of pickup orders, since many people work there, it makes sense it&#39;s the place where main demands from . | Many dropoff orders outside the Manhattan area maybe because people work/srudy in Manhattan, but live in areas like Queens/Brooklyn.. . | JFK Airport (the point in east north) maybe be a key point affect duration, since many orders back and forth within the city and JFK, it&#39;s a not short distance, may affect duration prediction alot. . | 2-5) store_and_fwd_flag . df_train_.store_and_fwd_flag.value_counts() . . N 1450599 Y 8045 Name: store_and_fwd_flag, dtype: int64 . About 0.5% (8045/1450599) of orders (store_and_fwd_flag=Y) are not sent immediately to vendor server, but hold in the memory of taxi, need to investigate if this affact data quality as well . 2-6) trip_duration . df_train_.head(1) . . id vendor_id pickup_datetime dropoff_datetime passenger_count pickup_longitude pickup_latitude dropoff_longitude dropoff_latitude store_and_fwd_flag ... pickup_month pickup_weekday dropoff_date dropoff_hour dropoff_year dropoff_month dropoff_weekday trip_duration_cal pickup_week_ pickup_weekday_ . 0 id2875421 | 2 | 2016-03-14 17:24:55 | 2016-03-14 17:32:30 | 1 | -73.982155 | 40.767937 | -73.96463 | 40.765602 | N | ... | 03 | 0 | 2016-03-14 | 17 | 2016 | 03 | 0 | 00:07:35 | 0 | Monday | . 1 rows × 24 columns . # trip duration overall distribution # remove outlier by only taking data under .97 quantile tripduration = df_train_[df_train_.trip_duration &lt; df_train_.trip_duration.quantile(.97)] tripduration.groupby(&#39;trip_duration&#39;).count()[&#39;id&#39;].plot() plt.xlabel(&#39;trip duration (sec)&#39;) plt.ylabel(&#39;trips counts&#39;) plt.title(&#39;Duration Distribution&#39;) . . &lt;matplotlib.text.Text at 0x12b918588&gt; . # pivot table # http://pbpython.com/pandas-pivot-table-explained.html #tripduration = df_train_[df_train_.trip_duration &lt; df_train_.trip_duration.quantile(.97)] pd.pivot_table(tripduration, index=&#39;pickup_hour&#39; ,aggfunc=np.mean)[&#39;trip_duration&#39;].plot(label=&#39;mean&#39;) pd.pivot_table(tripduration, index=&#39;pickup_hour&#39; ,aggfunc=np.median)[&#39;trip_duration&#39;].plot(label=&#39;median&#39;) pd.pivot_table(tripduration, index=&#39;pickup_hour&#39; ,aggfunc=np.std)[&#39;trip_duration&#39;].plot(label=&#39;std&#39;) plt.legend(loc=0) plt.xlabel(&#39;Pick up Hour (0-23)&#39;) plt.ylabel(&#39;orders counts &#39;) plt.title(&#39;Orders VS Pickup hour&#39;) plt.show() . . # plots trip duration on store_and_fwd_flag # (send back data to vendor server directly or save in taxi then upload because internet issues) plt.figure(figsize=(14,6)) sns.barplot(x=&#39;pickup_hour&#39;,y=&#39;trip_duration&#39;,data=df_train_,hue=&#39;store_and_fwd_flag&#39;) plt.xlabel(&#39;pickup_hour&#39;,fontsize=16) plt.ylabel(&#39;mean(trip_duration)&#39;,fontsize=16) . . &lt;matplotlib.text.Text at 0x10bdb8710&gt; . # duration VS. pickup hour in given months plt.figure(figsize=(14,6)) sns.pointplot(x=&#39;pickup_hour&#39;,y=&#39;trip_duration&#39;,data=tripduration,hue=&#39;pickup_month&#39;) plt.xlabel(&#39;pickup_hour&#39;,fontsize=16) plt.ylabel(&#39;mean(trip_duration)&#39;,fontsize=16) . . &lt;matplotlib.text.Text at 0x12b372710&gt; . # duration VS. pickup hour in weekdays plt.figure(figsize=(14,6)) sns.pointplot(x=&#39;pickup_hour&#39;,y=&#39;trip_duration&#39;,data=tripduration,hue=&#39;pickup_weekday_&#39;,hue_order=list(calendar.day_name)) plt.xlabel(&#39;pickup_hour&#39;,fontsize=16) plt.ylabel(&#39;mean(trip_duration)&#39;,fontsize=16) . . &lt;matplotlib.text.Text at 0x10c087470&gt; . df_train_.groupby(&#39;trip_duration&#39;).count()[&#39;id&#39;].tail(5) # 86392 sec means 23 hours # 2049578 sec means 23 days # which are all no make sense . . trip_duration 86392 1 1939736 1 2049578 1 2227612 1 3526282 1 Name: id, dtype: int64 . Duration is the prediction target in this competition : . Most trips finished within 6-10 minute (400-600 sec) | Some trips take too long/too fast are obvious wrong, maybe because of tech/maunal operation issues, should filter them in following process . | Duration are longer when store_and_fwd_flag = Y, maybe because internet is bad in areas off downtowm, imply taxi drivers much longer relatively. . | Duration RISE dramtically from 7 AM to 10 AM, maybe owing to traffic jam and people start moving to NYC from nearyby areas when daytime . | Months only affect duration a little bit ; while pickup hours seems may be infulence that more . | Weekday is apparently relative to duration. Duration are high duing wokday (Mon.-Fri.), since people work, taxi are much more busy to take people from Manhattan &lt;&gt; outside Manhattan . | 3) Feature engineering . # feature extract ### distance # https://www.kaggle.com/gaborfodor/from-eda-to-the-top-lb-0-377?scriptVersionId=1369021 # Haversine distance def get_haversine_distance(lat1, lng1, lat2, lng2): # km lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2)) AVG_EARTH_RADIUS = 6371 # km lat = lat2 - lat1 lng = lng2 - lng1 d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2 h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d)) return h # Manhattan distance # Taxi cant fly ! have to move in blocks/roads def get_manhattan_distance(lat1, lng1, lat2, lng2): # km a = get_haversine_distance(lat1, lng1, lat1, lng2) b = get_haversine_distance(lat1, lng1, lat2, lng1) return a + b # get direction (arc tangent angle) def get_direction(lat1, lng1, lat2, lng2): # theta AVG_EARTH_RADIUS = 6371 # km lng_delta_rad = np.radians(lng2 - lng1) lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2)) y = np.sin(lng_delta_rad) * np.cos(lat2) x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad) return np.degrees(np.arctan2(y, x)) ### ======================== ### def get_features(df): # km df_ = df.copy() ### USING .loc making return array ordering # distance df_.loc[:, &#39;distance_haversine&#39;] = get_haversine_distance( df_[&#39;pickup_latitude&#39;].values, df_[&#39;pickup_longitude&#39;].values, df_[&#39;dropoff_latitude&#39;].values, df_[&#39;dropoff_longitude&#39;].values) df_.loc[:, &#39;distance_manhattan&#39;] = get_manhattan_distance( df_[&#39;pickup_latitude&#39;].values, df_[&#39;pickup_longitude&#39;].values, df_[&#39;dropoff_latitude&#39;].values, df_[&#39;dropoff_longitude&#39;].values) # direction df_.loc[:, &#39;direction&#39;] = get_direction(df_[&#39;pickup_latitude&#39;].values, df_[&#39;pickup_longitude&#39;].values, df_[&#39;dropoff_latitude&#39;].values, df_[&#39;dropoff_longitude&#39;].values) # Get Average driving speed # km/hr # (km/sec = 3600 * (km/hr)) df_.loc[:, &#39;avg_speed_h&#39;] = 3600 * df_[&#39;distance_haversine&#39;] / df_[&#39;trip_duration&#39;] df_.loc[:, &#39;avg_speed_m&#39;] = 3600 * df_[&#39;distance_manhattan&#39;] / df_[&#39;trip_duration&#39;] return df_ . . # get speed (taxi velocity) #df_train_.loc[:, &#39;avg_speed_h&#39;] = 1000 * df_train_[&#39;distance_haversine&#39;] / df_train_[&#39;trip_duration&#39;] #df_train_.loc[:, &#39;avg_speed_m&#39;] = 1000 * df_train_[&#39;distance_manhattan&#39;] / df_train_[&#39;trip_duration&#39;] df_train_ = get_features(df_train_) . . df_train_.head(1) . . id vendor_id pickup_datetime dropoff_datetime passenger_count pickup_longitude pickup_latitude dropoff_longitude dropoff_latitude store_and_fwd_flag ... dropoff_month dropoff_weekday trip_duration_cal pickup_week_ pickup_weekday_ distance_haversine distance_manhattan direction avg_speed_h avg_speed_m . 0 id2875421 | 2 | 2016-03-14 17:24:55 | 2016-03-14 17:32:30 | 1 | -73.982155 | 40.767937 | -73.96463 | 40.765602 | N | ... | 03 | 0 | 00:07:35 | 0 | Monday | 1.498521 | 1.735433 | 99.970196 | 11.856428 | 13.730901 | . 1 rows × 29 columns . 4) Feature analysis . 4-1) Duration VS Distance . # distance VS duration sns.jointplot((df_train_[&quot;distance_manhattan&quot;][:10000]+1),(df_train_[&quot;trip_duration&quot;][:10000]+1),s=10,alpha=0.5,color=&#39;blue&#39;) plt.xlabel(&#39;mile&#39;) plt.ylabel(&#39;trip_duration&#39;) plt.xlim(0,30) plt.ylim(0,5000) plt.title(&#39;Distance VS Duration&#39;) plt.show() # log distance VS duration sns.jointplot(np.log(df_train_[&quot;distance_manhattan&quot;][:10000]+1),(df_train_[&quot;trip_duration&quot;][:10000]+1),s=10,alpha=0.5,color=&#39;purple&#39;) plt.xlim(0,30) plt.ylim(0,5000) plt.title(&#39;Logarithm Distance VS Duration&#39;) plt.xlabel(&#39;log(distance_manhattan)&#39;) plt.ylabel(&#39;trip_duration&#39;) plt.show() . . There are positive relations within distance and duration in the cases : . - (logarithm) haversine distance VS. duration - (logarithm) manhattan distance VS. duration . which fit common sense: trip takes longer when distance longer . ** log(distance) VS duration seems has better co-relation, will add log(distance) as new feature . 4-1&#39;) haversine VS manhattan . # ref # https://www.kaggle.com/hanriver0618/nyc-taxi-data-exploration-visualization # haversine distance VS duration # or u can plot all data points, still a linear relation #sns.jointplot(np.log10(df_train_[&quot;distance_haversine&quot;][:10000]+1),np.log10(df_train_[&quot;distance_haversine&quot;][:10000]+1),s=10,alpha=0.5,color=&#39;green&#39;) sns.jointplot((df_train_[&quot;distance_haversine&quot;][:10000]+1),(df_train_[&quot;distance_haversine&quot;][:10000]+1),s=10,alpha=0.5,color=&#39;green&#39;) plt.xlabel(&#39;log (mile)&#39;) plt.ylabel(&#39;log (trip_duration)&#39;) plt.show() # manhattan distance VS duration # or u can plot all data points, still a linear relation sns.jointplot((df_train_[&quot;distance_manhattan&quot;][:10000]+1),(df_train_[&quot;distance_haversine&quot;][:10000]+1),s=10,alpha=0.5,color=&#39;black&#39;) plt.xlabel(&#39;log (mile)&#39;) plt.ylabel(&#39;log (trip_duration)&#39;) plt.show() . . Haversine and manhattan (distance) are too linear co-related, . maybe only input one of them when modeling, avoiding possbile co-linear effect by too much relation features in same model . 4-2) Speed VS Times . # remove potential outliers for better visualization df_avg_speed = df_train_[(df_train_[&#39;avg_speed_h&#39;] &lt; df_train_[&#39;avg_speed_h&#39;].quantile(0.99))&amp; (df_train_[&#39;avg_speed_h&#39;] &gt; df_train_[&#39;avg_speed_h&#39;].quantile(0.01))] sns.distplot(df_avg_speed.avg_speed_h) plt.xlabel(&#39;average haversine speed [km/hr]&#39;,fontsize=16) plt.ylabel(&#39;relative amount&#39;,fontsize=16) plt.title(&#39;Speed Distribution&#39;,fontsize=16) plt.show() . . # Speed in different situations plt.figure(figsize=(20,12)) pd.pivot_table(df_train_, index=&#39;pickup_hour&#39;,columns=&#39;pickup_weekday&#39; ,aggfunc=np.mean)[&#39;avg_speed_h&#39;].plot() plt.xlabel(&#39;Pick up hour&#39;,fontsize=16) plt.ylabel(&#39;Speed [km/hr] &#39;,fontsize=16) plt.title(&#39;Driving Speed VS. Pickup Hour VS. Pickup Weekday&#39;,fontsize=16) . . &lt;matplotlib.text.Text at 0x12b5491d0&gt; . &lt;matplotlib.figure.Figure at 0x13759a3c8&gt; . # haversine speed visualization fig, ax = plt.subplots(nrows=3, sharey=True) fig.set_size_inches(12, 10) ax[0].plot(df_train_.groupby(&#39;pickup_hour&#39;).mean()[&#39;avg_speed_h&#39;], &#39;bo-&#39;, lw=2, alpha=0.7) ax[1].plot(df_train_.groupby(&#39;pickup_weekday&#39;).mean()[&#39;avg_speed_h&#39;], &#39;go-&#39;, lw=2, alpha=0.7) ax[2].plot(df_train_.groupby(&#39;pickup_date&#39;).mean()[&#39;avg_speed_h&#39;], &#39;ro-&#39;, lw=2, alpha=0.7) ax[0].set_xlabel(&#39;hour&#39;,fontsize=16) ax[1].set_xlabel(&#39;weekday&#39;,fontsize=16) ax[2].set_xlabel(&#39;date&#39;,fontsize=16) ax[0].set_ylabel(&#39;average speed&#39;,fontsize=16) ax[1].set_ylabel(&#39;average speed&#39;,fontsize=16) ax[2].set_ylabel(&#39;average speed&#39;,fontsize=16) fig.suptitle(&#39;Average Taxi Speed [km/hr] VS Pickup Times&#39;,fontsize=16) plt.show() . . Speed relate to Pickup Hour strongly . - 1. When in `non-rush hours`, taxi can drive faster - 2. Speed peak is within 5 am in weekday ; within 7 am in weekend - 3. Speed fluctuate periodically by days - 4. Average speed of around 15 km/h looks reasonable for NYC. . 4-3) Driving Direction . # pickup sns.lmplot(x=&quot;pickup_longitude&quot;, y=&quot;pickup_latitude&quot;, fit_reg=False, size=9, scatter_kws={&#39;alpha&#39;:0.05,&#39;s&#39;:5}, data=df_train_[( df_train_.pickup_longitude&gt;df_train_.pickup_longitude.quantile(0.005)) &amp;(df_train_.pickup_longitude&lt;df_train_.pickup_longitude.quantile(0.995)) &amp;(df_train_.pickup_latitude&gt;df_train_.pickup_latitude.quantile(0.005)) &amp;(df_train_.pickup_latitude&lt;df_train_.pickup_latitude.quantile(0.995))]) JFK_location=[-73.778203,40.641165] LaGuardia_location = [-73.873923,40.776935] NYC_center = [-73.977282,40.770940] ### transform locations to dataframe locations=pd.DataFrame({&#39;JFK&#39;:JFK_location, &#39;LaGuardia&#39;:LaGuardia_location, &#39;NYC&#39;:NYC_center}).T locations.columns=[&#39;lon&#39;,&#39;lat&#39;] ### plt.plot(JFK_location[0],JFK_location[1],&#39;o&#39;, color = &#39;r&#39;,alpha=0.9,markersize=10) plt.plot(LaGuardia_location[0],LaGuardia_location[1],&#39;o&#39;, color = &#39;r&#39;,alpha=0.9,markersize=10) plt.plot(NYC_center[0],NYC_center[1],&#39;o&#39;, color = &#39;r&#39;,alpha=0.9,markersize=10) plt.annotate(&#39;NYC_center&#39;, (NYC_center[0], NYC_center[1]), color = &#39;black&#39;, fontsize = 15) plt.annotate(&#39;LaGuardia&#39;, (LaGuardia_location[0], LaGuardia_location[1]), color = &#39;black&#39;, fontsize = 15) plt.annotate(&#39;JFK&#39;, (JFK_location[0], JFK_location[1]), color = &#39;black&#39;, fontsize = 15) plt.xlabel(&#39;Pickup Longitude&#39;,fontsize=16); plt.ylabel(&#39;Pickup Latitude&#39;,fontsize=16); plt.title(&#39;JFK &lt;--&gt; NYC, LAG &lt;&gt; NYC&#39;,fontsize=16) plt.show() . . # GET angles between main aiport and NYC downtown JFK_NYC= get_direction(JFK_location[0], JFK_location[1], NYC_center[0], NYC_center[1]) LAG_NYC= get_direction(LaGuardia_location[0], LaGuardia_location[1], NYC_center[0], NYC_center[1]) print (&#39;JFK - NYC_center angle = &#39;,JFK_NYC ) print (&#39;LAG - NYC_center angle = &#39;,LAG_NYC ) . . JFK - NYC_center angle = 169.801849301 LAG - NYC_center angle = -179.082799119 . sns.distplot(df_train_.direction,color=&#39;black&#39;) plt.xlabel(&#39;driving direction&#39;,fontsize=16) plt.ylabel(&#39;relative amount&#39;,fontsize=16) plt.title(&#39;Direction Distribution&#39;,fontsize=16) plt.show() . There are 2 peaks around 30 and -150 degrees in direction distribution . Maybe The 30 ones represent orders from JFK -&gt; Manhattan ; | The 150 ones represent orders form LAF -&gt; Manhattan ; | . | JFK - NYC_center angle = 169.801849301 | LAG - NYC_center angle = -179.082799119 | . -4.3) Clustering . from sklearn.cluster import MiniBatchKMeans # get lon &amp; lat clustering for following avg location speed calculation def get_clustering(df): coords = np.vstack((df_train[[&#39;pickup_latitude&#39;, &#39;pickup_longitude&#39;]].values, df_train[[&#39;dropoff_latitude&#39;, &#39;dropoff_longitude&#39;]].values, df_test[[&#39;pickup_latitude&#39;, &#39;pickup_longitude&#39;]].values, df_test[[&#39;dropoff_latitude&#39;, &#39;dropoff_longitude&#39;]].values)) df_ = df.copy() sample_ind = np.random.permutation(len(coords))[:500000] kmeans = MiniBatchKMeans(n_clusters=40, batch_size=10000).fit(coords[sample_ind]) df_.loc[:, &#39;pickup_cluster&#39;] = kmeans.predict(df_[[&#39;pickup_latitude&#39;, &#39;pickup_longitude&#39;]]) df_.loc[:, &#39;dropoff_cluster&#39;] = kmeans.predict(df_[[&#39;dropoff_latitude&#39;, &#39;dropoff_longitude&#39;]]) # a little bit modify clustering function here return df_,kmeans . . df_train_,kmeans = get_clustering(df_train_) . . # clustering pickup lon &amp; lat # https://www.kaggle.com/drgilermo/dynamics-of-new-york-city-animation # https://matplotlib.org/users/annotations.html fig,ax = plt.subplots(figsize = (10,8)) for label in df_train_.pickup_cluster.unique(): ax.plot(df_train_.pickup_longitude[df_train_.pickup_cluster == label],df_train_.pickup_latitude[df_train_.pickup_cluster == label],&#39;.&#39;, alpha = 0.9, markersize = 0.5) ax.plot(kmeans.cluster_centers_[label,1],kmeans.cluster_centers_[label,0],&#39;o&#39;, color = &#39;r&#39;) ax.annotate(label, (kmeans.cluster_centers_[label,1],kmeans.cluster_centers_[label,0]), color = &#39;black&#39;, fontsize = 10) plt.title(&#39;Pickup Clusters of New York&#39;,fontsize=20) plt.xlim(-74.02,-73.85) plt.ylim(40.65,40.85) plt.show() . . # clustering pickup lon &amp; lat # https://www.kaggle.com/drgilermo/dynamics-of-new-york-city-animation # https://matplotlib.org/users/annotations.html fig,ax = plt.subplots(figsize = (10,8)) for label in df_train_.dropoff_cluster.unique(): ax.plot(df_train_.dropoff_longitude[df_train_.dropoff_cluster == label],df_train_.dropoff_latitude[df_train_.dropoff_cluster == label],&#39;.&#39;, alpha = 0.9, markersize = 0.5) ax.plot(kmeans.cluster_centers_[label,1],kmeans.cluster_centers_[label,0],&#39;o&#39;, color = &#39;r&#39;) ax.annotate(label, (kmeans.cluster_centers_[label,1],kmeans.cluster_centers_[label,0]), color = &#39;black&#39;, fontsize = 10) plt.title(&#39;Dropoff Clusters of New York&#39;,fontsize=20) plt.xlim(-74.02,-73.85) plt.ylim(40.65,40.85) plt.show() . . 4.4) Avg speed, orders on clustering . df_train_.columns . . Index([&#39;id&#39;, &#39;vendor_id&#39;, &#39;pickup_datetime&#39;, &#39;dropoff_datetime&#39;, &#39;passenger_count&#39;, &#39;pickup_longitude&#39;, &#39;pickup_latitude&#39;, &#39;dropoff_longitude&#39;, &#39;dropoff_latitude&#39;, &#39;store_and_fwd_flag&#39;, &#39;trip_duration&#39;, &#39;pickup_date&#39;, &#39;pickup_hour&#39;, &#39;pickup_year&#39;, &#39;pickup_month&#39;, &#39;pickup_weekday&#39;, &#39;dropoff_date&#39;, &#39;dropoff_hour&#39;, &#39;dropoff_year&#39;, &#39;dropoff_month&#39;, &#39;dropoff_weekday&#39;, &#39;trip_duration_cal&#39;, &#39;pickup_week_&#39;, &#39;pickup_weekday_&#39;, &#39;distance_haversine&#39;, &#39;distance_manhattan&#39;, &#39;direction&#39;, &#39;avg_speed_h&#39;, &#39;avg_speed_m&#39;, &#39;pickup_cluster&#39;, &#39;dropoff_cluster&#39;], dtype=&#39;object&#39;) . # avg speed on cluster def avg_cluser_speed(df): df_ = df.copy() # avg speed on cluster avg_cluser_h = df_.groupby([&#39;pickup_cluster&#39;,&#39;dropoff_cluster&#39;]).mean()[&#39;avg_speed_h&#39;].reset_index() avg_cluser_h.columns = [&#39;pickup_cluster&#39;,&#39;dropoff_cluster&#39;,&#39;avg_speed_cluster_h&#39;] avg_cluser_m = df_.groupby([&#39;pickup_cluster&#39;,&#39;dropoff_cluster&#39;]).mean()[&#39;avg_speed_m&#39;].reset_index() avg_cluser_m.columns = [&#39;pickup_cluster&#39;,&#39;dropoff_cluster&#39;,&#39;avg_speed_cluster_m&#39;] # merge dataframe df_ = pd.merge(df_,avg_cluser_h, how = &#39;left&#39;, on = [&#39;pickup_cluster&#39;,&#39;dropoff_cluster&#39;]) df_ = pd.merge(df_,avg_cluser_m, how = &#39;left&#39;, on = [&#39;pickup_cluster&#39;,&#39;dropoff_cluster&#39;]) return df_ # avg duration on cluster def avg_cluser_duration(df): df_ = df.copy() # avg speed on cluster avg_cluser_duration = df_.groupby([&#39;pickup_cluster&#39;,&#39;dropoff_cluster&#39;]).mean()[&#39;trip_duration&#39;].reset_index() avg_cluser_duration.columns = [&#39;pickup_cluster&#39;,&#39;dropoff_cluster&#39;,&#39;avg_cluster_duration&#39;] # merge dataframe df_ = pd.merge(df_,avg_cluser_duration, how = &#39;left&#39;, on = [&#39;pickup_cluster&#39;,&#39;dropoff_cluster&#39;]) return df_ . . df_train_ = avg_cluser_speed(df_train_) df_train_ = avg_cluser_duration(df_train_) . . # plot avg speed as heat map # https://stackoverflow.com/questions/12857925/how-to-convert-data-values-into-color-information-for-matplotlib hot = plt.get_cmap(&#39;Purples&#39;) fig,ax = plt.subplots(figsize = (10,8)) for label in df_train_.dropoff_cluster.unique(): avg_cluster_speed= round(df_train_[df_train_.pickup_cluster ==label][&#39;avg_speed_cluster_h&#39;].mean()) ax.plot(df_train_.pickup_longitude[df_train_.pickup_cluster == label],df_train_.pickup_latitude[df_train_.pickup_cluster == label],&#39;.&#39; ,c=hot(avg_cluster_speed/10), alpha = 0.2, markersize = .3) if avg_cluster_speed == &#39;nan&#39;: pass else: ax.annotate(avg_cluster_speed, (kmeans.cluster_centers_[label,1],kmeans.cluster_centers_[label,0]), color = &#39;red&#39;, fontsize = 13) plt.title(&#39;Avg Cluster Speed (Haversine)&#39;,fontsize=20) plt.xlim(-74.02,-73.85) plt.ylim(40.65,40.85) plt.show() pd.DataFrame(df_train_.groupby(&#39;pickup_cluster&#39;).mean()[&#39;avg_speed_cluster_h&#39;]).transpose() . . pickup_cluster 0 1 2 3 4 5 6 7 8 9 ... 30 31 32 33 34 35 36 37 38 39 . avg_speed_cluster_h 14.998678 | 13.561559 | 28.074108 | 247.012039 | 21.382975 | 13.725013 | 13.649773 | 12.024319 | 16.427404 | 17.461386 | ... | 32.40242 | 12.85997 | 13.491272 | 16.68331 | 3.662986 | 17.530785 | 8.081368 | 15.406238 | 14.14637 | 16.839721 | . 1 rows × 40 columns . # plot avg speed as heat map # https://stackoverflow.com/questions/12857925/how-to-convert-data-values-into-color-information-for-matplotlib hot = plt.get_cmap(&#39;Purples&#39;) fig,ax = plt.subplots(figsize = (10,8)) for label in df_train_.dropoff_cluster.unique(): avg_cluster_speed= round(df_train_[df_train_.pickup_cluster ==label][&#39;avg_cluster_duration&#39;].mean()) ax.plot(df_train_.pickup_longitude[df_train_.pickup_cluster == label],df_train_.pickup_latitude[df_train_.pickup_cluster == label],&#39;.&#39; ,c=hot(avg_cluster_speed/10), alpha = 0.2, markersize = .3) if avg_cluster_speed == &#39;nan&#39;: pass else: ax.annotate(avg_cluster_speed, (kmeans.cluster_centers_[label,1],kmeans.cluster_centers_[label,0]), color = &#39;red&#39;, fontsize = 13) plt.title(&#39;Avg Cluster Duration &#39;,fontsize=20) plt.xlim(-74.02,-73.85) plt.ylim(40.65,40.85) plt.show() pd.DataFrame(df_train_.groupby(&#39;pickup_cluster&#39;).mean()[&#39;avg_cluster_duration&#39;]).transpose() . . pickup_cluster 0 1 2 3 4 5 6 7 8 9 ... 30 31 32 33 34 35 36 37 38 39 . avg_cluster_duration 804.200348 | 869.638242 | 2752.002555 | 500.923077 | 1926.69512 | 927.184799 | 836.056551 | 308.781818 | 912.685763 | 1005.314879 | ... | 3515.333333 | 901.554789 | 856.447082 | 880.928048 | 268.523256 | 788.984556 | 573.222222 | 796.988822 | 799.863082 | 742.207026 | . 1 rows × 40 columns . plt.scatter(df_train_[&#39;avg_speed_cluster_h&#39;],df_train_[&#39;avg_cluster_duration&#39;],c=&#39;black&#39;) plt.xlim(0,100) plt.ylim(0,5000) plt.title(&#39;Avg Cluster Speed VS. Avg Cluster Duration&#39;, fontsize=17) plt.show() . Out-of-downtown, and north area seems has higher avg cluster speed(16-21 km/hr), while middle and downtown area ubder 15 (km/hr) mostly . Maybe because they are far away city center, driver can drive fast | Longer distance make driver drive a little bit rush | . Avg cluster duration are longer in financial area(wall st.) and out-of-down area, maybe because . traffie is more crowded in such area | Drivers tend to drive faster in case if longer distance (same as above) | . There is a possible positive co-relation within Avg cluster speed and duration . Maybe driver has their own clock, can control driving time in a reasonable time interval , i.e. making driving time not too long and too short. | . .",
            "url": "https://yennanliu.github.io/yennj12_blog_V2/2020/04/03/nyc-taxi-eda.html",
            "relUrl": "/2020/04/03/nyc-taxi-eda.html",
            "date": " • Apr 3, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "My Project Ref",
            "content": "Portfolio website https://yennanliu.github.io/ (https://yennj12.js.org/) . Main Project | https://yennj12.js.org/main_project.html | . About Me | https://yennj12.js.org/about_me.html | . Overview | collections of my all side projects | . Contents | 1. applications projects 2. collections of utility codes | . Todo | 1. add blog page (sync with jekyll) 2. fix layout 3. add backend | . Tech | Html / CSS / Javascript | . My page . http://yennj12.js.org | . My blog . http://yennj12.js.org/yennj12_blog_V2 | .",
            "url": "https://yennanliu.github.io/yennj12_blog_V2/2020/04/03/my-project-ref.html",
            "relUrl": "/2020/04/03/my-project-ref.html",
            "date": " • Apr 3, 2020"
        }
        
    
  

  
  
      ,"page0": {
          "title": "",
          "content": "404 . Page not found :( . The requested page could not be found. .",
          "url": "https://yennanliu.github.io/yennj12_blog_V2/404.html",
          "relUrl": "/404.html",
          "date": ""
      }
      
  

  
      ,"page1": {
          "title": "About Me",
          "content": "A software engineer, focus on data. Interested in system design as well data product development (SLA). Want to focus on both high-level concepts and practical implementation. . Comment : SLA 1. . A service-level agreement (SLA) is a commitment between a service provider and a client. Particular aspects of the service – quality, availability, responsibilities – are agreed between the service provider and the service user. &#8617; . |",
          "url": "https://yennanliu.github.io/yennj12_blog_V2/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "",
          "content": "Hello and welcome to yennj12&#39;s blog. Please see below posts for reference. or visit my main page : https://yennj12.js.org/ .",
          "url": "https://yennanliu.github.io/yennj12_blog_V2/",
          "relUrl": "/",
          "date": ""
      }
      
  

  
  

  
      ,"page4": {
          "title": "yennj12.js.org",
          "content": "Please visit my website here .",
          "url": "https://yennanliu.github.io/yennj12_blog_V2/main_site/",
          "relUrl": "/main_site/",
          "date": ""
      }
      
  

  
  

  

  
  

  
  

}